{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Proposal - Predicting winners of the Oscars\n",
    "### By Jason Chan\n",
    "\n",
    "The original source of my data set can be found [here](https://bigml.com/user/academy_awards/gallery/dataset/5c6886e1eba31d73070017f5).\n",
    "\n",
    "The loaded csv version can be found under `data/movies.csv`. This data set contains a variety of information and fields about a large number of movies, ranging up until 2018. These fields contain information such as duration, genre, gross, user and critic reviews, etc. There are also fields for a variety of other awards and accolades, such BAFTA, the Golden Globes, Critics Choice awards, etc. In total there are 119 fields, and 1235 movie titles. Additionally, for each Oscar award, there is a field for whether the film was nominated for that particular Oscar award, as well as a field for whether it won the award. This will be the target variable - I can choose a specific Oscar award to train my model towards, such as Best Picture. At this early point, \"Best Picture\" is the most interesting of the Oscar awards that I could train my model for. However, in the future I can certainly extend this model to cover the variety of other Oscar awards. This problem is worth pursuing because the Oscars are the premier movie accolade, and winning an Oscar is considered the best possible accolade to win in the movie business. Therefore, people spend a significant time discussing and debating about the results of the Oscars. Being able to predict the winner of the Oscars would be an impressive feat. \n",
    "\n",
    "As I mentioned before, there are 1235 movie titles, and 119 fields. I will use all 1235 movie titles, but in my exploration of the fields, I may choose to exclude certain fields, especially if I decide to train my model towards one particular Oscar award. The dataset is relatively well documented, and tells us whether the feature values are numerical, categorical, text, list, or date field. Because of the sheer number of fields, I will not describe each field independently, but a quick overview can be found on the link. I will also likely exclude the fields pertaining to date, since film industry awards are typically given on a yearly basis anyway. There is also a synopsis field, which may lend to interesting NLP analysis. However, that is beyond the scope of this class, and thus I will not pursue it. Perhaps a cool extension to this project would also be to include analysis of movie synopses and see if movie award winnings can be predicted based on the content of the film. Unfortunately, it seems there is no clear documentation for this dataset on the website, other than the given title headings, so there may be some columns that I will have to guess the meaning of, such as: “popularity”, “rate”, and “metascore”. The latter two seem like scores out of 10 and out of 100, respectively. However, the popularity column is a numerical column where the numbers range on the order of several thousand, so I am uncertain about the meaning of the column. Despite the fact that this dataset is online, it seems that, according to the website where I obtained the dataset, there are no existing models and scripts posted publicly using this dataset. \n",
    "\n",
    "### Preprocessing the data  \n",
    "I chose to remove 50 of the columns, since these corresponded to values that I do not think will have a meaningful effect on the model, such as release date, or columns that, as of right now, are too complicated to process. In particular, I removed any columns with names that ended with “_nominated_categories”, or “_won_categories”, since the values in these columns could not just be single categories like “Best Actress”, but could also be a string form of a list, such as “Best Actress|Best Actor|Best Original Score|Best Picture”. Because of the form of this data, I cannot apply OneHotEncoding to it. For now, I can work with a simpler data set and train a simpler model. However, I think as this project goes on, perhaps I should find a way to include this information, as I think it would play an important role in the prediction of award winning. For example, it would probably be more likely for a film to win an Oscar for “Best Original Score” if it also won “Best Original Score” in the BAFTA awards.   \n",
    "\n",
    "Before I apply further preprocessing, the shape of the data at this stage is (1235, 69), meaning there are 1235 films and 69 features.   \n",
    "\n",
    "The majority of the features are either numerical, or categorical (“Yes” or “No”). I will apply a standard scaler to all the numerical features, and use pandas.replace() to the “Yes”/”No” features (simply to change all “No” to 0 and all “Yes” to 1). The only truly categorical feature is “certificate”, which has values such as “PG-13” or “R”. I will use a one hot encoder for this feature. Finally, for the purposes of this early stage work and model, I will the “Oscar_Best_Picture_won” feature as the target variable, and use a label encoder to transform that column.  \n",
    "\n",
    "By the end of the preprocessing, I have **75 total features**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Github Link To My Project](https://github.com/csjasonchan357/data1030-oscars-prediction-project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of all features:\n",
    "\n",
    "##### Categorical:  \n",
    "    certificate\n",
    "    \n",
    "##### Numerical:  \n",
    "    duration\n",
    "    rate\n",
    "    metascore\n",
    "    votes\n",
    "    gross\n",
    "    user_reviews\n",
    "    critic_reviews\n",
    "    popularity\n",
    "    awards_nominations\n",
    "    Oscar_nominated\n",
    "    Golden_Globes_won\n",
    "    Golden_Globes_nominated\n",
    "    BAFTA_won\n",
    "    BAFTA_nominated\n",
    "    Screen_Actors_Guild_won\n",
    "    Screen_Actors_Guild_nominated\n",
    "    Critics_Choice_won\n",
    "    Critics_Choice_nominated\n",
    "    Directors_Guild_won\n",
    "    Directors_Guild_nominated\n",
    "    Producers_Guild_won\n",
    "    Producers_Guild_nominated\n",
    "    Art_Directors_Guild_won\n",
    "    Art_Directors_Guild_nominated\n",
    "    Writers_Guild_won\n",
    "    Writers_Guild_nominated\n",
    "    Costume_Designers_Guild_won\n",
    "    Costume_Designers_Guild_nominated\n",
    "    Online_Film_Television_Association_won\n",
    "    Online_Film_Television_Association_nominated\n",
    "    Online_Film_Critics_Society_won\n",
    "    Online_Film_Critics_Society_nominated\n",
    "    People_Choice_won\n",
    "    People_Choice_nominated\n",
    "    London_Critics_Circle_Film_won\n",
    "    London_Critics_Circle_Film_nominated\n",
    "    American_Cinema_Editors_won\n",
    "    American_Cinema_Editors_nominated\n",
    "    Hollywood_Film_won\n",
    "    Hollywood_Film_nominated\n",
    "    Austin_Film_Critics_Association_won\n",
    "    Austin_Film_Critics_Association_nominated\n",
    "    Denver_Film_Critics_Society_won\n",
    "    Denver_Film_Critics_Society_nominated\n",
    "    Boston_Society_of_Film_Critics_won\n",
    "    Boston_Society_of_Film_Critics_nominated\n",
    "    New_York_Film_Critics_Circle_won\n",
    "    New_York_Film_Critics_Circle_nominated\n",
    "    Los_Angeles_Film_Critics_Association_won\n",
    "    Los_Angeles_Film_Critics_Association_nominated\n",
    "\n",
    "##### Boolean:  \n",
    "    Oscar_Best_Picture_nominated\n",
    "    Oscar_Best_Director_won\n",
    "    Oscar_Best_Director_nominated\n",
    "    Oscar_Best_Actor_won\n",
    "    Oscar_Best_Actor_nominated\n",
    "    Oscar_Best_Actress_won\n",
    "    Oscar_Best_Actress_nominated\n",
    "    Oscar_Best_Supporting_Actor_won\n",
    "    Oscar_Best_Supporting_Actor_nominated\n",
    "    Oscar_Best_Supporting_Actress_won\n",
    "    Oscar_Best_Supporting_Actress_nominated\n",
    "    Oscar_Best_AdaScreen_won\n",
    "    Oscar_Best_AdaScreen_nominated\n",
    "    Oscar_Best_OriScreen_won\n",
    "    Oscar_Best_OriScreen_nominated\n",
    "   \n",
    "##### ***Target Variable***:\n",
    "    Oscar_Best_Picture_won"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
