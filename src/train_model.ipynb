{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is: \n",
      "(1235, 1019)\n",
      "The balance of the dataset is: \n",
      "0    0.985425\n",
      "1    0.014575\n",
      "Name: Oscar_Best_Picture_won, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('/home/jovyan/data1030/data1030-oscars-prediction-project/data/pre_training_data.csv')\n",
    "print(\"The shape of the dataset is: \")\n",
    "print(df.shape)\n",
    "print(\"The balance of the dataset is: \")\n",
    "label = 'Oscar_Best_Picture_won'\n",
    "y = df[label]\n",
    "print(y.value_counts()/len(y))\n",
    "X = df.drop(columns=['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the features that have missing values, the fraction of missing values is:\n",
      "metascore         0.023482\n",
      "gross             0.034008\n",
      "user_reviews      0.011336\n",
      "critic_reviews    0.008097\n",
      "popularity        0.109312\n",
      "dtype: float64\n",
      "\n",
      "The total fraction of missing features in the data set is:\n",
      "0.12874493927125505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Of the features that have missing values, the fraction of missing values is:\")\n",
    "nulls = df.isnull().sum(axis=0)/df.shape[0]\n",
    "print(nulls[nulls > 0])\n",
    "print(\"\")\n",
    "print(\"The total fraction of missing features in the data set is:\")\n",
    "print(sum(df.isnull().sum(axis=1)!=0)/df.shape[0])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, make_scorer, recall_score, \\\n",
    "    precision_score, confusion_matrix, fbeta_score, average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "import xgboost\n",
    "import seaborn as sn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "num_cols = 'duration,rate,metascore,votes,gross,user_reviews,critic_reviews,popularity,awards_nominations,Oscar_nominated,Golden_Globes_nominated,BAFTA_won,BAFTA_nominated,Screen_Actors_Guild_won,Screen_Actors_Guild_nominated,Critics_Choice_won,Critics_Choice_nominated,Directors_Guild_won,Directors_Guild_nominated,Producers_Guild_won,Producers_Guild_nominated,Art_Directors_Guild_won,Art_Directors_Guild_nominated,Writers_Guild_won,Writers_Guild_nominated,Costume_Designers_Guild_won,Costume_Designers_Guild_nominated,Online_Film_Television_Association_won,Online_Film_Television_Association_nominated,Online_Film_Critics_Society_won,Online_Film_Critics_Society_nominated,People_Choice_won,People_Choice_nominated,London_Critics_Circle_Film_won,London_Critics_Circle_Film_nominated,American_Cinema_Editors_won,American_Cinema_Editors_nominated,Hollywood_Film_won,Hollywood_Film_nominated,Austin_Film_Critics_Association_won,Austin_Film_Critics_Association_nominated,Denver_Film_Critics_Society_won,Denver_Film_Critics_Society_nominated,Boston_Society_of_Film_Critics_won,Boston_Society_of_Film_Critics_nominated,New_York_Film_Critics_Circle_won,New_York_Film_Critics_Circle_nominated,Los_Angeles_Film_Critics_Association_won,Los_Angeles_Film_Critics_Association_nominated'\n",
    "num_cols = [x for x in num_cols.split(',')]\n",
    "mis_cols = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "[[243   0]\n",
      " [  0   4]]\n",
      "212.6930900000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.clock()\n",
    "random_state = 100\n",
    "X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "# continuous transformer setup\n",
    "cnts_transformer = Pipeline(steps = [('ss', StandardScaler())])\n",
    "# multivariate imputer setup\n",
    "impute_transformer = Pipeline(steps = [('mi', IterativeImputer(estimator = RandomForestRegressor(n_estimators=100), random_state=random_state))])\n",
    "# set up column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('impute', impute_transformer, mis_cols),\n",
    "        ('num', cnts_transformer, num_cols)])\n",
    "# create the pipeline: preprocessor + supervised ML method\n",
    "pipe = Pipeline(steps = [('preprocessor', preprocessor), ('clf', \n",
    "                    LogisticRegression(penalty = 'l1', solver='liblinear', max_iter = 1000, multi_class = 'auto'))])\n",
    "X_p = impute_transformer.fit_transform(cnts_transformer.fit_transform(X_other))\n",
    "lr = LogisticRegression(penalty = 'l1', solver='liblinear', max_iter = 1000, multi_class = 'auto')\n",
    "lr.fit(X_p, y_other)\n",
    "lr_pred = lr.predict(impute_transformer.transform(cnts_transformer.transform(X_test)))\n",
    "r_lr = recall_score(y_true = y_test, y_pred = lr_pred)\n",
    "p_lr = precision_score(y_true = y_test, y_pred = lr_pred)\n",
    "f_lr = fbeta_score(y_true = y_test, y_pred = lr_pred, beta = 1)\n",
    "cm = confusion_matrix(y_true = y_test, y_pred = lr_pred)\n",
    "print(r_lr)\n",
    "print(p_lr)\n",
    "print(f_lr)\n",
    "print(cm)\n",
    "stop = time.clock()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm):\n",
    "    data = cm\n",
    "    df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.set(font_scale=1.4)#for label size\n",
    "    ax = sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16}, fmt='.2f')\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_pipeline_kfold_GridSearchCV(X,y,random_state,n_folds):\n",
    "    X = X.fillna(-999)\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # continuous transformer setup\n",
    "    cnts_transformer = Pipeline(steps = [('ss', StandardScaler())])\n",
    "    # multivariate imputer setup\n",
    "    impute_transformer = Pipeline(steps = [('mi', IterativeImputer(estimator = \n",
    "                                RandomForestRegressor(n_estimators=100), random_state=random_state, missing_values = -999))])\n",
    "    # set up column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', cnts_transformer, num_cols),\n",
    "            ('impute', impute_transformer, mis_cols)])\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    pipe = Pipeline(steps = [('preprocessor', preprocessor), ('clf', \n",
    "                        LogisticRegression(penalty = 'l1', solver='liblinear', max_iter = 1000, multi_class = 'auto'))])\n",
    "    #parameters to tune\n",
    "    param_grid = {'clf__C': np.logspace(-4,4,20)}\n",
    "    #prepare scorers\n",
    "    scoring = {'recall': make_scorer(recall_score), 'precision' : make_scorer(precision_score), 'ap' : make_scorer(average_precision_score)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring = scoring, refit = 'ap', #scoring = make_scorer(average_precision_score),\n",
    "                            cv=kf, return_train_score = True,iid=True, verbose=10, n_jobs=-1)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_pred = best_model.predict(X_test)\n",
    "    best_precision = precision_score(y_test, best_pred) \n",
    "    best_recall = recall_score(y_test, best_pred)\n",
    "    best_f1 = fbeta_score(y_test, best_pred, 1)\n",
    "    return grid, grid.score(X_test, y_test), best_model, best_pred, best_precision, best_recall, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ap_scores = []\n",
    "lr_precision_scores = []\n",
    "lr_recall_scores = []\n",
    "lr_f1_scores = []\n",
    "lr_models = []\n",
    "\n",
    "print(\"Training Logistic Regression Model\")\n",
    "for i in range(6):\n",
    "    lr_grid,lr_ap_score, lr_best_model, lr_best_pred, lr_best_precision, lr_best_recall, lr_best_f1 = LR_pipeline_kfold_GridSearchCV(X,y,10*i,4)\n",
    "    print(\"________________________________________________________\")\n",
    "    print(\"Random State:\",10*i)\n",
    "    print(\"Best Parameters:\")\n",
    "    print(lr_grid.best_params_)\n",
    "    print('best CV score:',lr_grid.best_score_)\n",
    "    print('average precision score:',lr_ap_score)\n",
    "    print('precision: ', lr_best_precision)\n",
    "    print('recall: ', lr_best_recall)\n",
    "    print('f1: ', lr_best_f1)\n",
    "    lr_ap_scores.append(lr_ap_score)\n",
    "    lr_precision_scores.append(lr_best_precision)\n",
    "    lr_recall_scores.append(lr_best_recall)\n",
    "    lr_f1_scores.append(lr_best_f1)\n",
    "    lr_models.append(lr_best_model)\n",
    "    print(\"________________________________________________________\")\n",
    "print(\"________________________________________________________\")\n",
    "print('Logistic Regression Results')\n",
    "print('test average precision :',np.around(np.mean(lr_ap_scores),2),'+/-',np.around(np.std(lr_ap_scores),2))\n",
    "print('test precision :',np.around(np.mean(lr_precision_scores),2),'+/-',np.around(np.std(lr_precision_scores),2))\n",
    "print('test recall: ',np.around(np.mean(lr_recall_scores),2),'+/-',np.around(np.std(lr_recall_scores),2))\n",
    "print('test f1: ',np.around(np.mean(lr_f1_scores),2),'+/-',np.around(np.std(lr_f1_scores),2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Training Logistic Regression Model\n",
    "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.1min\n",
    "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.6min\n",
    "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.6min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  4.0min\n",
    "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.2min\n",
    "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  7.8min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  9.1min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 10.4min\n",
    "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 12.0min finished\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
    "  \" reached.\", ConvergenceWarning)\n",
    "________________________________________________________\n",
    "Random State: 0\n",
    "Best Parameters:\n",
    "{'clf__C': 206.913808111479}\n",
    "best CV score: 0.3687584345479082\n",
    "average precision score: 0.7540485829959515\n",
    "precision:  1.0\n",
    "recall:  0.75\n",
    "f1:  0.8571428571428571\n",
    "________________________________________________________\n",
    "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   57.7s\n",
    "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.4min\n",
    "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.3min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.2min\n",
    "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.6min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.9min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  7.1min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  8.1min\n",
    "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  9.8min finished\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
    "  \" reached.\", ConvergenceWarning)\n",
    "________________________________________________________\n",
    "Random State: 10\n",
    "Best Parameters:\n",
    "{'clf__C': 1438.44988828766}\n",
    "best CV score: 0.4647435897435897\n",
    "average precision score: 0.3790485829959514\n",
    "precision:  0.5\n",
    "recall:  0.75\n",
    "f1:  0.6\n",
    "________________________________________________________\n",
    "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   57.4s\n",
    "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.4min\n",
    "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.2min\n",
    "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.8min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.0min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.0min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  6.4min\n",
    "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  7.3min\n",
    "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  9.1min finished\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
    "  \" reached.\", ConvergenceWarning)\n",
    "________________________________________________________\n",
    "Random State: 20\n",
    "Best Parameters:\n",
    "{'clf__C': 0.23357214690901212}\n",
    "best CV score: 0.43016194331983804\n",
    "average precision score: 0.34143049932523617\n",
    "precision:  0.6666666666666666\n",
    "recall:  0.5\n",
    "f1:  0.5714285714285715\n",
    "________________________________________________________\n",
    "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   55.3s\n",
    "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.4min\n",
    "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.2min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.7min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.0min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.3min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  6.4min\n",
    "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  7.5min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  9.1min finished\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
    "  \" reached.\", ConvergenceWarning)\n",
    "________________________________________________________\n",
    "Random State: 30\n",
    "Best Parameters:\n",
    "{'clf__C': 0.615848211066026}\n",
    "best CV score: 0.39996626180836703\n",
    "average precision score: 0.13714574898785425\n",
    "precision:  0.5\n",
    "recall:  0.25\n",
    "f1:  0.3333333333333333\n",
    "________________________________________________________\n",
    "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   55.5s\n",
    "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.3min\n",
    "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.2min\n",
    "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.1min\n",
    "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.7min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.7min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  6.9min\n",
    "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  8.0min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  9.6min finished\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
    "  \" reached.\", ConvergenceWarning)\n",
    "________________________________________________________\n",
    "Random State: 40\n",
    "Best Parameters:\n",
    "{'clf__C': 3792.690190732246}\n",
    "best CV score: 0.506578947368421\n",
    "average precision score: 0.34143049932523617\n",
    "precision:  0.6666666666666666\n",
    "recall:  0.5\n",
    "f1:  0.5714285714285715\n",
    "________________________________________________________\n",
    "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n",
    "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   55.3s\n",
    "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.3min\n",
    "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.2min\n",
    "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.1min\n",
    "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.7min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.6min\n",
    "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  6.9min\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
    "  \"timeout or by a memory leak.\", UserWarning\n",
    "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  7.9min\n",
    "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  9.6min finished\n",
    "/Users/Jason/.local/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
    "  \" reached.\", ConvergenceWarning)\n",
    "________________________________________________________\n",
    "Random State: 50\n",
    "Best Parameters:\n",
    "{'clf__C': 0.23357214690901212}\n",
    "best CV score: 0.45006747638326583\n",
    "average precision score: 0.13714574898785425\n",
    "precision:  0.5\n",
    "recall:  0.25\n",
    "f1:  0.3333333333333333\n",
    "________________________________________________________\n",
    "________________________________________________________\n",
    "Logistic Regression Results\n",
    "test average precision : 0.35 +/- 0.21\n",
    "test precision : 0.64 +/- 0.18\n",
    "test recall:  0.5 +/- 0.2\n",
    "test f1:  0.54 +/- 0.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOGISTIC REGRESSION RESULTS**\n",
    "\n",
    "Metric|Mean|St Dev\n",
    "---|---|---\n",
    "Average Precision|0.35|0.2\n",
    "Precision|0.64|0.18\n",
    "Recall|0.5|0.2\n",
    "F1|0.54|0.18\n",
    "\n",
    "Best hyperparameters: `C` $= 1.0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_pipeline_kfold_GridSearchCV(X,y,random_state,n_folds):\n",
    "    X = X.fillna(-999)\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # continuous transformer setup\n",
    "    cnts_transformer = Pipeline(steps = [('ss', StandardScaler())])\n",
    "    # multivariate imputer setup\n",
    "    impute_transformer = Pipeline(steps = [('mi', IterativeImputer(estimator = \n",
    "                                RandomForestRegressor(n_estimators=100), random_state=random_state, missing_values = -999))])\n",
    "    # set up column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', cnts_transformer, num_cols),\n",
    "            ('impute', impute_transformer, mis_cols)])\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    pipe = Pipeline(steps = [('preprocessor', preprocessor), ('clf', \n",
    "                        RandomForestClassifier(n_estimators = 100, random_state = random_state))])\n",
    "    #parameters to tune\n",
    "    param_grid = {'clf__max_depth': np.sort(np.concatenate([[2],  np.logspace(1,2,2)/2 , np.logspace(1,2,2)])),\n",
    "                 'clf__min_samples_split': np.arange(2,23,5)}\n",
    "    #prepare scorers\n",
    "    scoring = {'recall': make_scorer(recall_score), 'precision' : make_scorer(precision_score), 'ap' : make_scorer(average_precision_score)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring = scoring, refit = 'ap', #scoring = make_scorer(average_precision_score),\n",
    "                            cv=kf, return_train_score = True,iid=True, verbose=10, n_jobs=-1)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_pred = best_model.predict(X_test)\n",
    "    best_precision = precision_score(y_test, best_pred) \n",
    "    best_recall = recall_score(y_test, best_pred)\n",
    "    best_f1 = fbeta_score(y_test, best_pred, 1)\n",
    "    return grid, grid.score(X_test, y_test), best_model, best_pred, best_precision, best_recall, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Model\n",
      "Iteration 0\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 12.8min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 0\n",
      "Best Parameters:\n",
      "{'clf__max_depth': 5.0, 'clf__min_samples_split': 2}\n",
      "best CV score: 0.07591093117408906\n",
      "average precision score: 0.26214574898785425\n",
      "precision:  1.0\n",
      "recall:  0.25\n",
      "f1:  0.4\n",
      "________________________________________________________\n",
      "Iteration 1\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 12.6min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 10\n",
      "Best Parameters:\n",
      "{'clf__max_depth': 5.0, 'clf__min_samples_split': 2}\n",
      "best CV score: 0.18454790823211875\n",
      "average precision score: 0.016194331983805668\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1:  0.0\n",
      "________________________________________________________\n",
      "Iteration 2\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 12.6min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 20\n",
      "Best Parameters:\n",
      "{'clf__max_depth': 2.0, 'clf__min_samples_split': 2}\n",
      "best CV score: 0.01417004048582996\n",
      "average precision score: 0.016194331983805668\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1:  0.0\n",
      "________________________________________________________\n",
      "Iteration 3\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 12.5min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 30\n",
      "Best Parameters:\n",
      "{'clf__max_depth': 5.0, 'clf__min_samples_split': 2}\n",
      "best CV score: 0.07489878542510121\n",
      "average precision score: 0.016194331983805668\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1:  0.0\n",
      "________________________________________________________\n",
      "Iteration 4\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 12.6min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 40\n",
      "Best Parameters:\n",
      "{'clf__max_depth': 5.0, 'clf__min_samples_split': 2}\n",
      "best CV score: 0.2601214574898785\n",
      "average precision score: 0.016194331983805668\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1:  0.0\n",
      "________________________________________________________\n",
      "Iteration 5\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 12.5min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 50\n",
      "Best Parameters:\n",
      "{'clf__max_depth': 5.0, 'clf__min_samples_split': 2}\n",
      "best CV score: 0.12651821862348175\n",
      "average precision score: 0.26214574898785425\n",
      "precision:  1.0\n",
      "recall:  0.25\n",
      "f1:  0.4\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "Logistic Regression Results\n",
      "test average precision : 0.1 +/- 0.12\n",
      "test precision : 0.33 +/- 0.47\n",
      "test recall:  0.08 +/- 0.12\n",
      "test f1:  0.13 +/- 0.19\n"
     ]
    }
   ],
   "source": [
    "rf_ap_scores = []\n",
    "rf_precision_scores = []\n",
    "rf_recall_scores = []\n",
    "rf_f1_scores = []\n",
    "\n",
    "print(\"Training Random Forest Model\")\n",
    "for i in range(6):\n",
    "    print(\"Iteration\", i)\n",
    "    rf_grid,rf_ap_score, rf_best_model, rf_best_pred, rf_best_precision, rf_best_recall, rf_best_f1 = RF_pipeline_kfold_GridSearchCV(X,y,10*i,4)\n",
    "    print(\"________________________________________________________\")\n",
    "    print(\"Random State:\",10*i)\n",
    "    print(\"Best Parameters:\")\n",
    "    print(rf_grid.best_params_)\n",
    "    print('best CV score:',rf_grid.best_score_)\n",
    "    print('average precision score:',rf_ap_score)\n",
    "    print('precision: ', rf_best_precision)\n",
    "    print('recall: ', rf_best_recall)\n",
    "    print('f1: ', rf_best_f1)\n",
    "    rf_ap_scores.append(rf_ap_score)\n",
    "    rf_precision_scores.append(rf_best_precision)\n",
    "    rf_recall_scores.append(rf_best_recall)\n",
    "    rf_f1_scores.append(rf_best_f1)\n",
    "    print(\"________________________________________________________\")\n",
    "print(\"________________________________________________________\")\n",
    "print('Random Forest Model Results')\n",
    "print('test average precision :',np.around(np.mean(rf_ap_scores),2),'+/-',np.around(np.std(rf_ap_scores),2))\n",
    "print('test precision :',np.around(np.mean(rf_precision_scores),2),'+/-',np.around(np.std(rf_precision_scores),2))\n",
    "print('test recall: ',np.around(np.mean(rf_recall_scores),2),'+/-',np.around(np.std(rf_recall_scores),2))\n",
    "print('test f1: ',np.around(np.mean(rf_f1_scores),2),'+/-',np.around(np.std(rf_f1_scores),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RANDOM FOREST RESULTS**\n",
    "\n",
    "Metric|Mean|St Dev\n",
    "---|---|---\n",
    "Average Precision|0.1|0.12\n",
    "Precision|0.33|0.47\n",
    "Recall|0.08|0.12\n",
    "F1|0.13|0.19\n",
    "\n",
    "Best hyperparameters: `max_depth` $= 5.0$, `min_samples_split` $= 2.0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "def XGB_pipeline_kfold_GridSearchCV(X,y,random_state,n_folds):\n",
    "    X = X.fillna(-999)\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # continuous transformer setup\n",
    "    cnts_transformer = Pipeline(steps = [('ss', StandardScaler())])\n",
    "    # multivariate imputer setup\n",
    "    impute_transformer = Pipeline(steps = [('mi', IterativeImputer(estimator = \n",
    "                                RandomForestRegressor(n_estimators=100), random_state=random_state, missing_values = -999))])\n",
    "    # set up column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', cnts_transformer, num_cols),\n",
    "            ('impute', impute_transformer, mis_cols)])\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    pipe = Pipeline(steps = [('preprocessor', preprocessor), ('clf', \n",
    "                        xgboost.XGBClassifier())])\n",
    "    #parameters to tune\n",
    "    param_grid = {'clf__colsample_bytree': [0.75, 1.0], \n",
    "                  'clf__max_depth':[4,6,8] , \n",
    "                  'clf__min_child_weight': [2,5,10]}\n",
    "    #prepare scorers\n",
    "    scoring = {'recall': make_scorer(recall_score), 'precision' : make_scorer(precision_score), 'ap' : make_scorer(average_precision_score)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring = scoring, refit = 'ap', #scoring = make_scorer(average_precision_score),\n",
    "                            cv=kf, return_train_score = True,iid=True, verbose=10, n_jobs=-1)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_pred = best_model.predict(X_test)\n",
    "    best_precision = precision_score(y_test, best_pred) \n",
    "    best_recall = recall_score(y_test, best_pred)\n",
    "    best_f1 = fbeta_score(y_test, best_pred, 1)\n",
    "    return grid, grid.score(X_test, y_test), best_model, best_pred, best_precision, best_recall, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost Model\n",
      "Iteration 0\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  9.9min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 0\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 1.0, 'clf__max_depth': 4, 'clf__min_child_weight': 2}\n",
      "best CV score: 0.30802968960863697\n",
      "average precision score: 0.7540485829959515\n",
      "precision:  1.0\n",
      "recall:  0.75\n",
      "f1:  0.8571428571428571\n",
      "________________________________________________________\n",
      "Iteration 1\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  9.4min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 10\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 0.75, 'clf__max_depth': 4, 'clf__min_child_weight': 2}\n",
      "best CV score: 0.2462887989203779\n",
      "average precision score: 0.13714574898785425\n",
      "precision:  0.5\n",
      "recall:  0.25\n",
      "f1:  0.3333333333333333\n",
      "________________________________________________________\n",
      "Iteration 2\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  9.0min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 20\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 0.75, 'clf__max_depth': 4, 'clf__min_child_weight': 2}\n",
      "best CV score: 0.2800269905533063\n",
      "average precision score: 0.13714574898785425\n",
      "precision:  0.5\n",
      "recall:  0.25\n",
      "f1:  0.3333333333333333\n",
      "________________________________________________________\n",
      "Iteration 3\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  9.3min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 30\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 1.0, 'clf__max_depth': 4, 'clf__min_child_weight': 2}\n",
      "best CV score: 0.2388663967611336\n",
      "average precision score: 0.26214574898785425\n",
      "precision:  1.0\n",
      "recall:  0.25\n",
      "f1:  0.4\n",
      "________________________________________________________\n",
      "Iteration 4\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  9.3min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 40\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 0.75, 'clf__max_depth': 4, 'clf__min_child_weight': 2}\n",
      "best CV score: 0.45175438596491224\n",
      "average precision score: 0.016194331983805668\n",
      "precision:  0.0\n",
      "recall:  0.0\n",
      "f1:  0.0\n",
      "________________________________________________________\n",
      "Iteration 5\n",
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:  9.2min finished\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 50\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 0.75, 'clf__max_depth': 4, 'clf__min_child_weight': 2}\n",
      "best CV score: 0.29014844804318485\n",
      "average precision score: 0.5080971659919028\n",
      "precision:  1.0\n",
      "recall:  0.5\n",
      "f1:  0.6666666666666666\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "Random Forest Model Results\n",
      "test average precision : 0.3 +/- 0.25\n",
      "test precision : 0.67 +/- 0.37\n",
      "test recall:  0.33 +/- 0.24\n",
      "test f1:  0.43 +/- 0.27\n"
     ]
    }
   ],
   "source": [
    "xgb_ap_scores = []\n",
    "xgb_precision_scores = []\n",
    "xgb_recall_scores = []\n",
    "xgb_f1_scores = []\n",
    "\n",
    "print(\"Training XGBoost Model\")\n",
    "for i in range(6):\n",
    "    print(\"Iteration\", i)\n",
    "    xgb_grid,xgb_ap_score, xgb_best_model, xgb_best_pred, xgb_best_precision, xgb_best_recall, xgb_best_f1 = XGB_pipeline_kfold_GridSearchCV(X,y,10*i,4)\n",
    "    print(\"________________________________________________________\")\n",
    "    print(\"Random State:\",10*i)\n",
    "    print(\"Best Parameters:\")\n",
    "    print(xgb_grid.best_params_)\n",
    "    print('best CV score:',xgb_grid.best_score_)\n",
    "    print('average precision score:',xgb_ap_score)\n",
    "    print('precision: ', xgb_best_precision)\n",
    "    print('recall: ', xgb_best_recall)\n",
    "    print('f1: ', xgb_best_f1)\n",
    "    xgb_ap_scores.append(xgb_ap_score)\n",
    "    xgb_precision_scores.append(xgb_best_precision)\n",
    "    xgb_recall_scores.append(xgb_best_recall)\n",
    "    xgb_f1_scores.append(xgb_best_f1)\n",
    "    print(\"________________________________________________________\")\n",
    "print(\"________________________________________________________\")\n",
    "print('XGBoost Model Results')\n",
    "print('test average precision :',np.around(np.mean(xgb_ap_scores),2),'+/-',np.around(np.std(xgb_ap_scores),2))\n",
    "print('test precision :',np.around(np.mean(xgb_precision_scores),2),'+/-',np.around(np.std(xgb_precision_scores),2))\n",
    "print('test recall: ',np.around(np.mean(xgb_recall_scores),2),'+/-',np.around(np.std(xgb_recall_scores),2))\n",
    "print('test f1: ',np.around(np.mean(xgb_f1_scores),2),'+/-',np.around(np.std(xgb_f1_scores),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost RESULTS**\n",
    "\n",
    "Metric|Mean|St Dev\n",
    "---|---|---\n",
    "Average Precision|0.3|0.25\n",
    "Precision|0.67|0.37\n",
    "Recall|0.33|0.24\n",
    "F1|0.43|0.27\n",
    "\n",
    "Best hyperparameters: `colsample_bytree` $= 0.75$, `max_depth` $= 4$, `min_child_weight` $=2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost No Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "def XGB_pipeline_kfold_GridSearchCV(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # continuous transformer setup\n",
    "    cnts_transformer = Pipeline(steps = [('ss', StandardScaler())])\n",
    "    # multivariate imputer setup\n",
    "    impute_transformer = Pipeline(steps = [('mi', IterativeImputer(estimator = \n",
    "                                RandomForestRegressor(n_estimators=100), random_state=random_state, missing_values = -999))])\n",
    "    # set up column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', cnts_transformer, num_cols)])\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    pipe = Pipeline(steps = [('preprocessor', preprocessor), ('clf', \n",
    "                        xgboost.XGBClassifier())])\n",
    "    #parameters to tune\n",
    "    param_grid = {'clf__colsample_bytree': [0.5, 0.75, 1.0], \n",
    "                  'clf__max_depth':[2,4,6,8] , \n",
    "                  'clf__min_child_weight': [2,5,10],\n",
    "                  'clf__subsample': [0.5, 0.75, 1.0],\n",
    "                  'clf__learning_rate': [0.01, 0.05,0.1]}\n",
    "    #prepare scorers\n",
    "    scoring = {'recall': make_scorer(recall_score), 'precision' : make_scorer(precision_score), 'ap' : make_scorer(average_precision_score)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring = scoring, refit = 'ap', #scoring = make_scorer(average_precision_score),\n",
    "                            cv=kf, return_train_score = True,iid=True, verbose=10, n_jobs=-1)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_pred = best_model.predict(X_test)\n",
    "    best_precision = precision_score(y_test, best_pred) \n",
    "    best_recall = recall_score(y_test, best_pred)\n",
    "    best_f1 = fbeta_score(y_test, best_pred, 1)\n",
    "    return grid, grid.score(X_test, y_test), best_model, best_pred, best_precision, best_recall, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost Model\n",
      "Iteration 0\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1999s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 179 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done 259 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 301 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 347 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 393 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 443 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 493 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 547 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 601 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done 659 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 717 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=-1)]: Done 779 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done 841 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=-1)]: Done 907 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done 973 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1043 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1113 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1187 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1261 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1293 out of 1296 | elapsed:  1.3min remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 0\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.01, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.416497975708502\n",
      "average precision score: 0.45404858299595136\n",
      "precision:  0.6\n",
      "recall:  0.75\n",
      "f1:  0.6666666666666665\n",
      "________________________________________________________\n",
      "Iteration 1\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1444s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 278 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 350 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 472 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=-1)]: Done 518 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 564 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done 614 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=-1)]: Done 664 tasks      | elapsed:   41.9s\n",
      "[Parallel(n_jobs=-1)]: Done 718 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done 772 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=-1)]: Done 830 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done 950 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1012 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1078 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1214 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1284 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 10\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 0.5, 'clf__learning_rate': 0.1, 'clf__max_depth': 4, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.328272604588394\n",
      "average precision score: 0.26214574898785425\n",
      "precision:  1.0\n",
      "recall:  0.25\n",
      "f1:  0.4\n",
      "________________________________________________________\n",
      "Iteration 2\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1269s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 278 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 350 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 472 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=-1)]: Done 518 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 564 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done 614 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done 664 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 718 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done 772 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done 830 tasks      | elapsed:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   49.8s\n",
      "[Parallel(n_jobs=-1)]: Done 950 tasks      | elapsed:   54.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1012 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1078 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1214 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1284 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 20\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.01, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.45607287449392714\n",
      "average precision score: 0.5665485829959515\n",
      "precision:  0.75\n",
      "recall:  0.75\n",
      "f1:  0.75\n",
      "________________________________________________________\n",
      "Iteration 3\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1333s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 278 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 350 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 472 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 518 tasks      | elapsed:   27.5s\n",
      "[Parallel(n_jobs=-1)]: Done 564 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 614 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done 664 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done 718 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 772 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done 830 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=-1)]: Done 950 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1012 tasks      | elapsed:   58.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1078 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1214 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1284 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 30\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.01, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.37044534412955465\n",
      "average precision score: 0.45404858299595136\n",
      "precision:  0.6\n",
      "recall:  0.75\n",
      "f1:  0.6666666666666665\n",
      "________________________________________________________\n",
      "Iteration 4\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1379s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 278 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 350 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done 472 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=-1)]: Done 518 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 564 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 614 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=-1)]: Done 664 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done 718 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=-1)]: Done 772 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done 830 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   49.1s\n",
      "[Parallel(n_jobs=-1)]: Done 950 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1012 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1078 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1214 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1284 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 40\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.01, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.5714237516869095\n",
      "average precision score: 0.25809716599190285\n",
      "precision:  0.5\n",
      "recall:  0.5\n",
      "f1:  0.5\n",
      "________________________________________________________\n",
      "Iteration 5\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1327s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 278 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done 350 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 472 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 518 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done 564 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=-1)]: Done 614 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done 664 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done 718 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=-1)]: Done 772 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=-1)]: Done 830 tasks      | elapsed:   54.1s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done 950 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1012 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1078 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1214 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1284 tasks      | elapsed:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 50\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.01, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.5421052631578948\n",
      "average precision score: 0.34143049932523617\n",
      "precision:  0.6666666666666666\n",
      "recall:  0.5\n",
      "f1:  0.5714285714285715\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "XGBoost No Impute Model Results\n",
      "test average precision : 0.39 +/- 0.11\n",
      "test precision : 0.69 +/- 0.16\n",
      "test recall:  0.58 +/- 0.19\n",
      "test f1:  0.59 +/- 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "xgb2_ap_scores = []\n",
    "xgb2_precision_scores = []\n",
    "xgb2_recall_scores = []\n",
    "xgb2_f1_scores = []\n",
    "xgb2_models = []\n",
    "\n",
    "print(\"Training XGBoost Model\")\n",
    "for i in range(6):\n",
    "    print(\"Iteration\", i)\n",
    "    xgb2_grid,xgb2_ap_score, xgb2_best_model, xgb2_best_pred, xgb2_best_precision, xgb2_best_recall, xgb2_best_f1 = XGB_pipeline_kfold_GridSearchCV(X,y,10*i,4)\n",
    "    print(\"________________________________________________________\")\n",
    "    print(\"Random State:\",10*i)\n",
    "    print(\"Best Parameters:\")\n",
    "    print(xgb2_grid.best_params_)\n",
    "    print('best CV score:',xgb2_grid.best_score_)\n",
    "    print('average precision score:',xgb2_ap_score)\n",
    "    print('precision: ', xgb2_best_precision)\n",
    "    print('recall: ', xgb2_best_recall)\n",
    "    print('f1: ', xgb2_best_f1)\n",
    "    xgb2_ap_scores.append(xgb2_ap_score)\n",
    "    xgb2_precision_scores.append(xgb2_best_precision)\n",
    "    xgb2_recall_scores.append(xgb2_best_recall)\n",
    "    xgb2_f1_scores.append(xgb2_best_f1)\n",
    "    xgb2_models.append(xgb2_best_model)\n",
    "    print(\"________________________________________________________\")\n",
    "print(\"________________________________________________________\")\n",
    "print('XGBoost No Impute Model Results')\n",
    "print('test average precision :',np.around(np.mean(xgb2_ap_scores),2),'+/-',np.around(np.std(xgb2_ap_scores),2))\n",
    "print('test precision :',np.around(np.mean(xgb2_precision_scores),2),'+/-',np.around(np.std(xgb2_precision_scores),2))\n",
    "print('test recall: ',np.around(np.mean(xgb2_recall_scores),2),'+/-',np.around(np.std(xgb2_recall_scores),2))\n",
    "print('test f1: ',np.around(np.mean(xgb2_f1_scores),2),'+/-',np.around(np.std(xgb2_f1_scores),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost No Impute RESULTS**\n",
    "\n",
    "Metric|Mean|St Dev\n",
    "---|---|---\n",
    "Average Precision|0.39|0.11\n",
    "Precision|0.69|0.16\n",
    "Recall|0.58|0.19\n",
    "F1|0.59|0.12\n",
    "\n",
    "Best hyperparameters: `colsample_bytree` $= 1.0$, `max_depth` $= 2$, `min_child_weight` $=2$, `learning_rate` $=0.01$, `subsample` $=1.0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test model\n",
    "metrics\n",
    "confusion matrix, accuracy, precision, recall, AUROC, AU-PR Curve\n",
    "\n",
    "RandomForestClassification.feature_importances_  \n",
    "https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "\n",
    "XGBoost.get_score(importance_type = ...)  \n",
    "https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.Booster.get_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(xgb2_models, open('/home/jovyan/data1030/data1030-oscars-prediction-project/results/models.sav', 'wb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost sources:\n",
    "\n",
    "https://www.kaggle.com/phunter/xgboost-with-gridsearchcv  \n",
    "https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost  \n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/  \n",
    "https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree', 'max_depth', 'min_child_weight', 'subsample'}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param1 = {'colsample_bytree': 1.0,\n",
    " 'eta': 0.01,\n",
    " 'eval_metric': 'mae',\n",
    " 'max_depth': 10,\n",
    " 'min_child_weight': 6,\n",
    " 'objective': 'reg:linear',\n",
    " 'subsample': 0.8}\n",
    "param2 = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "param3 = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "set(param1.keys()).intersection(set(param2.keys())).intersection(set(param3.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def SVM_pipeline_kfold_GridSearchCV(X,y,random_state,n_folds):\n",
    "    X = X.fillna(-999)\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # continuous transformer setup\n",
    "    cnts_transformer = Pipeline(steps = [('ss', StandardScaler())])\n",
    "    # multivariate imputer setup\n",
    "    impute_transformer = Pipeline(steps = [('mi', IterativeImputer(estimator = \n",
    "                                RandomForestRegressor(n_estimators=100), random_state=random_state, missing_values = -999))])\n",
    "    # set up column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', cnts_transformer, num_cols),\n",
    "            ('impute', impute_transformer, mis_cols)])\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    pipe = Pipeline(steps = [('preprocessor', preprocessor), ('clf', SVC())])\n",
    "    #parameters to tune\n",
    "    param_grid = {'clf__C': np.logspace(-4,4,5),\n",
    "                 'clf__gamma': np.logspace(-4,4,5)}\n",
    "    #prepare scorers\n",
    "    scoring = {'recall': make_scorer(recall_score), 'precision' : make_scorer(precision_score), 'ap' : make_scorer(average_precision_score)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring = scoring, refit = 'ap', #scoring = make_scorer(average_precision_score),\n",
    "                            cv=kf, return_train_score = True,iid=True, verbose=10, n_jobs=-1)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_pred = best_model.predict(X_test)\n",
    "    best_precision = precision_score(y_test, best_pred) \n",
    "    best_recall = recall_score(y_test, best_pred)\n",
    "    best_f1 = fbeta_score(y_test, best_pred, 1)\n",
    "    return grid, grid.score(X_test, y_test), best_model, best_pred, best_precision, best_recall, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM Model\n",
      "Iteration 0\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   17.3s\n",
      "exception calling callback for <Future at 0x7f0519c5cf98 state=finished raised TerminatedWorkerError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 309, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 731, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 759, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\", line 716, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 510, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\", line 151, in submit\n",
      "    fn, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 1022, in submit\n",
      "    raise self._flags.broken\n",
      "joblib.externals.loky.process_executor.TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-42bbe15777cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iteration\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msvm_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_ap_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_best_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_best_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_best_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_best_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_best_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM_pipeline_kfold_GridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"________________________________________________________\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random State:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-215-9f6cc1a657ad>\u001b[0m in \u001b[0;36mSVM_pipeline_kfold_GridSearchCV\u001b[0;34m(X, y, random_state, n_folds)\u001b[0m\n\u001b[1;32m     26\u001b[0m                             cv=kf, return_train_score = True,iid=True, verbose=10, n_jobs=-1)\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# do kfold CV on _other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_other\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_other\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mbest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/_base.py\u001b[0m in \u001b[0;36m_invoke_callbacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exception calling callback for %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \"\"\"\n\u001b[0;32m--> 731\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSafeFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_future_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             return super(_ReusablePoolExecutor, self).submit(\n\u001b[0;32m--> 151\u001b[0;31m                 fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 raise ShutdownExecutorError(\n",
      "\u001b[0;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "svm_ap_scores = []\n",
    "svm_precision_scores = []\n",
    "svm_recall_scores = []\n",
    "svm_f1_scores = []\n",
    "svm_models= []\n",
    "\n",
    "print(\"Training SVM Model\")\n",
    "for i in range(1):\n",
    "    print(\"Iteration\", i)\n",
    "    svm_grid, svm_ap_score, svm_best_model, svm_best_pred, svm_best_precision, svm_best_recall, svm_best_f1 = SVM_pipeline_kfold_GridSearchCV(X,y,10*i,4)\n",
    "    print(\"________________________________________________________\")\n",
    "    print(\"Random State:\",10*i)\n",
    "    print(\"Best Parameters:\")\n",
    "    print(svm_grid.best_params_)\n",
    "    print('best CV score:',svm_grid.best_score_)\n",
    "    print('average precision score:',svm_ap_score)\n",
    "    print('precision: ', svm_best_precision)\n",
    "    print('recall: ', svm_best_recall)\n",
    "    print('f1: ', svm_best_f1)\n",
    "    svm_ap_scores.append(svm_ap_score)\n",
    "    svm_precision_scores.append(svm_best_precision)\n",
    "    svm_recall_scores.append(svm_best_recall)\n",
    "    svm_f1_scores.append(svm_best_f1)\n",
    "    svm_models.append(svm_best_model)\n",
    "    print(\"________________________________________________________\")\n",
    "print(\"________________________________________________________\")\n",
    "print('SVM Results')\n",
    "print('test average precision :',np.around(np.mean(svm_ap_scores),2),'+/-',np.around(np.std(svm_ap_scores),2))\n",
    "print('test precision :',np.around(np.mean(svm_precision_scores),2),'+/svm_-',np.around(np.std(svm_precision_scores),2))\n",
    "print('test recall: ',np.around(np.mean(svm_recall_scores),2),'+/-',np.around(np.std(svm_recall_scores),2))\n",
    "print('test f1: ',np.around(np.mean(svm_f1_scores),2),'+/-',np.around(np.std(svm_f1_scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
