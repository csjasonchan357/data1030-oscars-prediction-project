{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is: \n",
      "(1235, 1019)\n",
      "The balance of the dataset is: \n",
      "0    0.985425\n",
      "1    0.014575\n",
      "Name: Oscar_Best_Picture_won, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('/home/jovyan/data1030/data1030-oscars-prediction-project/data/pre_training_data.csv')\n",
    "print(\"The shape of the dataset is: \")\n",
    "print(df.shape)\n",
    "print(\"The balance of the dataset is: \")\n",
    "label = 'Oscar_Best_Picture_won'\n",
    "y = df[label]\n",
    "print(y.value_counts()/len(y))\n",
    "X = df.drop(columns=['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the features that have missing values, the fraction of missing values is:\n",
      "metascore         0.023482\n",
      "gross             0.034008\n",
      "user_reviews      0.011336\n",
      "critic_reviews    0.008097\n",
      "popularity        0.109312\n",
      "dtype: float64\n",
      "\n",
      "The total fraction of missing features in the data set is:\n",
      "0.12874493927125505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Of the features that have missing values, the fraction of missing values is:\")\n",
    "nulls = df.isnull().sum(axis=0)/df.shape[0]\n",
    "print(nulls[nulls > 0])\n",
    "print(\"\")\n",
    "print(\"The total fraction of missing features in the data set is:\")\n",
    "print(sum(df.isnull().sum(axis=1)!=0)/df.shape[0])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, make_scorer, recall_score, \\\n",
    "    precision_score, confusion_matrix, fbeta_score, average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "num_cols = 'duration,rate,metascore,votes,gross,user_reviews,critic_reviews,popularity,awards_nominations,Oscar_nominated,Golden_Globes_nominated,BAFTA_won,BAFTA_nominated,Screen_Actors_Guild_won,Screen_Actors_Guild_nominated,Critics_Choice_won,Critics_Choice_nominated,Directors_Guild_won,Directors_Guild_nominated,Producers_Guild_won,Producers_Guild_nominated,Art_Directors_Guild_won,Art_Directors_Guild_nominated,Writers_Guild_won,Writers_Guild_nominated,Costume_Designers_Guild_won,Costume_Designers_Guild_nominated,Online_Film_Television_Association_won,Online_Film_Television_Association_nominated,Online_Film_Critics_Society_won,Online_Film_Critics_Society_nominated,People_Choice_won,People_Choice_nominated,London_Critics_Circle_Film_won,London_Critics_Circle_Film_nominated,American_Cinema_Editors_won,American_Cinema_Editors_nominated,Hollywood_Film_won,Hollywood_Film_nominated,Austin_Film_Critics_Association_won,Austin_Film_Critics_Association_nominated,Denver_Film_Critics_Society_won,Denver_Film_Critics_Society_nominated,Boston_Society_of_Film_Critics_won,Boston_Society_of_Film_Critics_nominated,New_York_Film_Critics_Circle_won,New_York_Film_Critics_Circle_nominated,Los_Angeles_Film_Critics_Association_won,Los_Angeles_Film_Critics_Association_nominated'\n",
    "num_cols = [x for x in num_cols.split(',')]\n",
    "mis_cols = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "[[243   0]\n",
      " [  0   4]]\n",
      "212.6930900000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.clock()\n",
    "random_state = 100\n",
    "X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state)\n",
    "# continuous transformer setup\n",
    "cnts_transformer = Pipeline(steps = [('ss', StandardScaler())])\n",
    "# multivariate imputer setup\n",
    "impute_transformer = Pipeline(steps = [('mi', IterativeImputer(estimator = RandomForestRegressor(n_estimators=100), random_state=random_state))])\n",
    "# set up column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('impute', impute_transformer, mis_cols),\n",
    "        ('num', cnts_transformer, num_cols)])\n",
    "# create the pipeline: preprocessor + supervised ML method\n",
    "pipe = Pipeline(steps = [('preprocessor', preprocessor), ('clf', \n",
    "                    LogisticRegression(penalty = 'l1', solver='liblinear', max_iter = 1000, multi_class = 'auto'))])\n",
    "X_p = impute_transformer.fit_transform(cnts_transformer.fit_transform(X_other))\n",
    "lr = LogisticRegression(penalty = 'l1', solver='liblinear', max_iter = 1000, multi_class = 'auto')\n",
    "lr.fit(X_p, y_other)\n",
    "lr_pred = lr.predict(impute_transformer.transform(cnts_transformer.transform(X_test)))\n",
    "r_lr = recall_score(y_true = y_test, y_pred = lr_pred)\n",
    "p_lr = precision_score(y_true = y_test, y_pred = lr_pred)\n",
    "f_lr = fbeta_score(y_true = y_test, y_pred = lr_pred, beta = 1)\n",
    "cm = confusion_matrix(y_true = y_test, y_pred = lr_pred)\n",
    "print(r_lr)\n",
    "print(p_lr)\n",
    "print(f_lr)\n",
    "print(cm)\n",
    "stop = time.clock()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm):\n",
    "    data = cm\n",
    "    df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sn.set(font_scale=1.4)#for label size\n",
    "    ax = sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16}, fmt='.2f')\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_pipeline_kfold_GridSearchCV(X,y,random_state,n_folds):\n",
    "    X = X.fillna(-999)\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # continuous transformer setup\n",
    "    cnts_transformer = Pipeline(steps = [('ss', StandardScaler())])\n",
    "    # multivariate imputer setup\n",
    "    impute_transformer = Pipeline(steps = [('mi', IterativeImputer(estimator = \n",
    "                                RandomForestRegressor(n_estimators=100), random_state=random_state, missing_values = -999))])\n",
    "    # set up column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', cnts_transformer, num_cols),\n",
    "            ('impute', impute_transformer, mis_cols)])\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    pipe = Pipeline(steps = [('preprocessor', preprocessor), ('clf', \n",
    "                        LogisticRegression(penalty = 'l1', solver='liblinear', max_iter = 1000, multi_class = 'auto'))])\n",
    "    #parameters to tune\n",
    "    param_grid = {'clf__C': np.logspace(-2,4,10)}\n",
    "    #prepare scorers\n",
    "    scoring = {'recall': make_scorer(recall_score), 'precision' : make_scorer(precision_score), 'ap' : make_scorer(average_precision_score)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring = scoring, refit = 'ap', #scoring = make_scorer(average_precision_score),\n",
    "                            cv=kf, return_train_score = True,iid=True, verbose=10, n_jobs=-1)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_pred = best_model.predict(X_test)\n",
    "    best_precision = precision_score(y_test, best_pred) \n",
    "    best_recall = recall_score(y_test, best_pred)\n",
    "    best_f1 = fbeta_score(y_test, best_pred, 1)\n",
    "    return grid, grid.score(X_test, y_test), best_model, best_pred, best_precision, best_recall, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression Model\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  40 | elapsed:  6.6min remaining:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  6.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 0\n",
      "Best Parameters:\n",
      "{'clf__C': 1.0}\n",
      "best CV score: 0.44797570850202434\n",
      "average precision score: 0.7540485829959515\n",
      "precision:  1.0\n",
      "recall:  0.75\n",
      "f1:  0.8571428571428571\n",
      "________________________________________________________\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   49.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  40 | elapsed:  5.2min remaining:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  5.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 10\n",
      "Best Parameters:\n",
      "{'clf__C': 2154.4346900318824}\n",
      "best CV score: 0.4647435897435897\n",
      "average precision score: 0.3790485829959514\n",
      "precision:  0.5\n",
      "recall:  0.75\n",
      "f1:  0.6\n",
      "________________________________________________________\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  40 | elapsed:  6.6min remaining:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  6.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 20\n",
      "Best Parameters:\n",
      "{'clf__C': 0.21544346900318834}\n",
      "best CV score: 0.43016194331983804\n",
      "average precision score: 0.34143049932523617\n",
      "precision:  0.6666666666666666\n",
      "recall:  0.5\n",
      "f1:  0.5714285714285715\n",
      "________________________________________________________\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  40 | elapsed:  6.0min remaining:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  6.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 30\n",
      "Best Parameters:\n",
      "{'clf__C': 2154.4346900318824}\n",
      "best CV score: 0.3827597840755735\n",
      "average precision score: 0.09547908232118758\n",
      "precision:  0.3333333333333333\n",
      "recall:  0.25\n",
      "f1:  0.28571428571428575\n",
      "________________________________________________________\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  40 | elapsed:  7.2min remaining:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  7.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  7.5min finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 40\n",
      "Best Parameters:\n",
      "{'clf__C': 10000.0}\n",
      "best CV score: 0.506578947368421\n",
      "average precision score: 0.34143049932523617\n",
      "precision:  0.6666666666666666\n",
      "recall:  0.5\n",
      "f1:  0.5714285714285715\n",
      "________________________________________________________\n",
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   56.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  40 | elapsed:  6.3min remaining:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  6.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/impute/_iterative.py:603: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 50\n",
      "Best Parameters:\n",
      "{'clf__C': 0.21544346900318834}\n",
      "best CV score: 0.45006747638326583\n",
      "average precision score: 0.26214574898785425\n",
      "precision:  1.0\n",
      "recall:  0.25\n",
      "f1:  0.4\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "Logistic Regression Results\n",
      "test average precision : 0.36 +/- 0.2\n",
      "test precision : 0.69 +/- 0.24\n",
      "test recall:  0.5 +/- 0.2\n",
      "test f1:  0.55 +/- 0.18\n"
     ]
    }
   ],
   "source": [
    "ap_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "print(\"Training Logistic Regression Model\")\n",
    "for i in range(6):\n",
    "    grid,ap_score, best_model, best_pred, best_precision, best_recall, best_f1 = LR_pipeline_kfold_GridSearchCV(X,y,10*i,4)\n",
    "    print(\"________________________________________________________\")\n",
    "    print(\"Random State:\",10*i)\n",
    "    print(\"Best Parameters:\")\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('average precision score:',ap_score)\n",
    "    print('precision: ', best_precision)\n",
    "    print('recall: ', best_recall)\n",
    "    print('f1: ', best_f1)\n",
    "    ap_scores.append(ap_score)\n",
    "    precision_scores.append(best_precision)\n",
    "    recall_scores.append(best_recall)\n",
    "    f1_scores.append(best_f1)\n",
    "    print(\"________________________________________________________\")\n",
    "print(\"________________________________________________________\")\n",
    "print('Logistic Regression Results')\n",
    "print('test average precision :',np.around(np.mean(ap_scores),2),'+/-',np.around(np.std(ap_scores),2))\n",
    "print('test precision :',np.around(np.mean(precision_scores),2),'+/-',np.around(np.std(precision_scores),2))\n",
    "print('test recall: ',np.around(np.mean(recall_scores),2),'+/-',np.around(np.std(recall_scores),2))\n",
    "print('test f1: ',np.around(np.mean(f1_scores),2),'+/-',np.around(np.std(f1_scores),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOGISTIC REGRESSION RESULTS**\n",
    "\n",
    "Metric|Mean|St Dev\n",
    "---|---|---\n",
    "Average Precision|0.36|0.2\n",
    "Precision|0.69|0.24\n",
    "Recall|0.5|0.2\n",
    "F1|0.55|0.18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_pipeline_kfold_GridSearchCV(X,y,random_state,n_folds):\n",
    "    X = X.fillna(-999)\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # continuous transformer setup\n",
    "    cnts_transformer = Pipeline(steps = [('ss', StandardScaler())])\n",
    "    # multivariate imputer setup\n",
    "    impute_transformer = Pipeline(steps = [('mi', IterativeImputer(estimator = \n",
    "                                RandomForestRegressor(n_estimators=100), random_state=random_state, missing_values = -999))])\n",
    "    # set up column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', cnts_transformer, num_cols),\n",
    "            ('impute', impute_transformer, mis_cols)])\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    pipe = Pipeline(steps = [('preprocessor', preprocessor), ('clf', \n",
    "                        RandomForestClassifier(n_estimators = 100, random_state = random_state))])\n",
    "    #parameters to tune\n",
    "    param_grid = {'clf__max_depth': np.sort(np.concatenate([[2],  np.logspace(1,2,2)/2 , np.logspace(1,2,2)])),\n",
    "                 'clf__min_samples_split': np.arange(2,23,5)}\n",
    "    #prepare scorers\n",
    "    scoring = {'recall': make_scorer(recall_score), 'precision' : make_scorer(precision_score), 'ap' : make_scorer(average_precision_score)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring = scoring, refit = 'ap', #scoring = make_scorer(average_precision_score),\n",
    "                            cv=kf, return_train_score = True,iid=True, verbose=10, n_jobs=-1)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_pred = best_model.predict(X_test)\n",
    "    best_precision = precision_score(y_test, best_pred) \n",
    "    best_recall = recall_score(y_test, best_pred)\n",
    "    best_f1 = fbeta_score(y_test, best_pred, 1)\n",
    "    return grid, grid.score(X_test, y_test), best_model, best_pred, best_precision, best_recall, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Model\n",
      "Iteration 0\n",
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   33.1s\n"
     ]
    }
   ],
   "source": [
    "ap_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "print(\"Training Random Forest Model\")\n",
    "for i in range(6):\n",
    "    print(\"Iteration\", i)\n",
    "    grid,ap_score, best_model, best_pred, best_precision, best_recall, best_f1 = RF_pipeline_kfold_GridSearchCV(X,y,10*i,4)\n",
    "    print(\"________________________________________________________\")\n",
    "    print(\"Random State:\",10*i)\n",
    "    print(\"Best Parameters:\")\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('average precision score:',ap_score)\n",
    "    print('precision: ', best_precision)\n",
    "    print('recall: ', best_recall)\n",
    "    print('f1: ', best_f1)\n",
    "    ap_scores.append(ap_score)\n",
    "    precision_scores.append(best_precision)\n",
    "    recall_scores.append(best_recall)\n",
    "    f1_scores.append(best_f1)\n",
    "    print(\"________________________________________________________\")\n",
    "print(\"________________________________________________________\")\n",
    "print('Logistic Regression Results')\n",
    "print('test average precision :',np.around(np.mean(ap_scores),2),'+/-',np.around(np.std(ap_scores),2))\n",
    "print('test precision :',np.around(np.mean(precision_scores),2),'+/-',np.around(np.std(precision_scores),2))\n",
    "print('test recall: ',np.around(np.mean(recall_scores),2),'+/-',np.around(np.std(recall_scores),2))\n",
    "print('test f1: ',np.around(np.mean(f1_scores),2),'+/-',np.around(np.std(f1_scores),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test model\n",
    "metrics\n",
    "confusion matrix, accuracy, precision, recall, AUROC, AU-PR Curve\n",
    "\n",
    "RandomForestClassification.feature_importances_  \n",
    "https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "\n",
    "XGBoost.get_score(importance_type = ...)  \n",
    "https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.Booster.get_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
