{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, recall_score, precision_score, \\\n",
    "    confusion_matrix, fbeta_score, average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "import xgboost\n",
    "import seaborn as sn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jovyan/data1030/data1030-oscars-prediction-project/data/pre_training_data.csv')\n",
    "label = 'Oscar_Best_Picture_won'\n",
    "y = df[label]\n",
    "X = df.drop(columns=['movie'])\n",
    "\n",
    "num_cols = 'duration,rate,metascore,votes,gross,user_reviews,critic_reviews,popularity,awards_nominations,Oscar_nominated,Golden_Globes_nominated,BAFTA_won,BAFTA_nominated,Screen_Actors_Guild_won,Screen_Actors_Guild_nominated,Critics_Choice_won,Critics_Choice_nominated,Directors_Guild_won,Directors_Guild_nominated,Producers_Guild_won,Producers_Guild_nominated,Art_Directors_Guild_won,Art_Directors_Guild_nominated,Writers_Guild_won,Writers_Guild_nominated,Costume_Designers_Guild_won,Costume_Designers_Guild_nominated,Online_Film_Television_Association_won,Online_Film_Television_Association_nominated,Online_Film_Critics_Society_won,Online_Film_Critics_Society_nominated,People_Choice_won,People_Choice_nominated,London_Critics_Circle_Film_won,London_Critics_Circle_Film_nominated,American_Cinema_Editors_won,American_Cinema_Editors_nominated,Hollywood_Film_won,Hollywood_Film_nominated,Austin_Film_Critics_Association_won,Austin_Film_Critics_Association_nominated,Denver_Film_Critics_Society_won,Denver_Film_Critics_Society_nominated,Boston_Society_of_Film_Critics_won,Boston_Society_of_Film_Critics_nominated,New_York_Film_Critics_Circle_won,New_York_Film_Critics_Circle_nominated,Los_Angeles_Film_Critics_Association_won,Los_Angeles_Film_Critics_Association_nominated'\n",
    "num_cols = [x for x in num_cols.split(',')]\n",
    "mis_cols = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as ma\n",
    "import scipy.stats as st\n",
    "\n",
    "def checks_input_mcar_tests(data):\n",
    "    \"\"\" Checks whether the input parameter of class McarTests is correct\n",
    "            Parameters\n",
    "            ----------\n",
    "            data:\n",
    "                The input of McarTests specified as 'data'\n",
    "            Returns\n",
    "            -------\n",
    "            bool\n",
    "                True if input is correct\n",
    "            \"\"\"\n",
    "\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        print(\"Error: Data should be a Pandas DataFrame\")\n",
    "        return False\n",
    "\n",
    "    if not any(data.dtypes.values == np.float):\n",
    "        if not any(data.dtypes.values == np.int):\n",
    "            print(\"Error: Dataset cannot contain other value types than floats and/or integers\")\n",
    "            return False\n",
    "\n",
    "    if not data.isnull().values.any():\n",
    "        print(\"Error: No NaN's in given data\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def mcar_test(data):\n",
    "    \"\"\" Implementation of Little's MCAR test\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Pandas DataFrame\n",
    "        An incomplete dataset with samples as index and variables as columns\n",
    "    Returns\n",
    "    -------\n",
    "    p_value: Float\n",
    "        This value is the outcome of a chi-square statistical test, testing whether the null hypothesis\n",
    "        'the missingness mechanism of the incomplete dataset is MCAR' can be rejected.\n",
    "    \"\"\"\n",
    "\n",
    "    if not checks_input_mcar_tests(data):\n",
    "        raise Exception(\"Input not correct\")\n",
    "\n",
    "    dataset = data.copy()\n",
    "    vars = dataset.dtypes.index.values\n",
    "    n_var = dataset.shape[1]\n",
    "\n",
    "    # mean and covariance estimates\n",
    "    # ideally, this is done with a maximum likelihood estimator\n",
    "    gmean = dataset.mean()\n",
    "    gcov = dataset.cov()\n",
    "\n",
    "    # set up missing data patterns\n",
    "    r = 1 * dataset.isnull()\n",
    "    mdp = np.dot(r, list(map(lambda x: ma.pow(2, x), range(n_var))))\n",
    "    sorted_mdp = sorted(np.unique(mdp))\n",
    "    n_pat = len(sorted_mdp)\n",
    "    correct_mdp = list(map(lambda x: sorted_mdp.index(x), mdp))\n",
    "    dataset['mdp'] = pd.Series(correct_mdp, index=dataset.index)\n",
    "\n",
    "    # calculate statistic and df\n",
    "    pj = 0\n",
    "    d2 = 0\n",
    "    for i in range(n_pat):\n",
    "        dataset_temp = dataset.loc[dataset['mdp'] == i, vars]\n",
    "        select_vars = ~dataset_temp.isnull().any()\n",
    "        pj += np.sum(select_vars)\n",
    "        select_vars = vars[select_vars]\n",
    "        means = dataset_temp[select_vars].mean() - gmean[select_vars]\n",
    "        select_cov = gcov.loc[select_vars, select_vars]\n",
    "        mj = len(dataset_temp)\n",
    "        parta = np.dot(means.T, np.linalg.solve(select_cov, np.identity(select_cov.shape[1])))\n",
    "        d2 += mj * (np.dot(parta, means))\n",
    "\n",
    "    df = pj - n_var\n",
    "\n",
    "    # perform test and save output\n",
    "    p_value = 1 - st.chi2.cdf(d2, df)\n",
    "\n",
    "    return p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://journals.sagepub.com/doi/pdf/10.1177/1536867X1301300407\n",
    "\n",
    "See page 5 of the above, search \"singular\". This is why my MCAR test is failing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3461e0bb33dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmcar_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-a11ce9f7f5ae>\u001b[0m in \u001b[0;36mmcar_test\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mselect_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselect_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mmj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mparta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_cov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_cov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0md2\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmj\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DD->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'dd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "X.shape\n",
    "mcar_test(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1235, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.columns[X.isnull().any(axis=0)]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcar_test(X[X.columns[X.isnull().any(axis=0)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = pd.read_csv('/home/jovyan/data1030/data1030-oscars-prediction-project/data/movies.csv')\n",
    "oscars_2019 = list(mv.index[mv['year'] == 2018])\n",
    "X_2019 = X.loc[oscars_2019]\n",
    "X_train = X.drop(oscars_2019)\n",
    "y_train = y.drop(oscars_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "def XGB_pipeline_kfold_GridSearchCV(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # continuous transformer setup\n",
    "    cnts_transformer = Pipeline(steps = [('ss', StandardScaler())])\n",
    "    # multivariate imputer setup\n",
    "    impute_transformer = Pipeline(steps = [('mi', IterativeImputer(estimator = \n",
    "                                RandomForestRegressor(n_estimators=100), random_state=random_state, missing_values = -999))])\n",
    "    # set up column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', cnts_transformer, num_cols)])\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    pipe = Pipeline(steps = [('preprocessor', preprocessor), ('clf', \n",
    "                        xgboost.XGBClassifier())])\n",
    "    #parameters to tune\n",
    "    param_grid = {'clf__colsample_bytree': [0.5, 0.75, 1.0], \n",
    "                  'clf__max_depth':[2,4,6,8] , \n",
    "                  'clf__min_child_weight': [2,5,10],\n",
    "                  'clf__subsample': [0.5, 0.75, 1.0],\n",
    "                  'clf__learning_rate': [0.01, 0.05,0.1]}\n",
    "    #prepare scorers\n",
    "    scoring = {'recall': make_scorer(recall_score), 'precision' : make_scorer(precision_score), 'ap' : make_scorer(average_precision_score)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring = scoring, refit = 'ap', #scoring = make_scorer(average_precision_score),\n",
    "                            cv=kf, return_train_score = True,iid=True, verbose=1, n_jobs=-1)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_pred = best_model.predict(X_test)\n",
    "    best_precision = precision_score(y_test, best_pred) \n",
    "    best_recall = recall_score(y_test, best_pred)\n",
    "    best_f1 = fbeta_score(y_test, best_pred, 1)\n",
    "    return grid, grid.score(X_test, y_test), best_model, best_pred, best_precision, best_recall, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X,y):    \n",
    "    xgb2_ap_scores = []\n",
    "    xgb2_precision_scores = []\n",
    "    xgb2_recall_scores = []\n",
    "    xgb2_f1_scores = []\n",
    "    xgb2_models = []\n",
    "\n",
    "    print(\"Training XGBoost Model\")\n",
    "    for i in range(6):\n",
    "        print(\"Iteration\", i)\n",
    "        xgb2_grid,xgb2_ap_score, xgb2_best_model, xgb2_best_pred, xgb2_best_precision, xgb2_best_recall, xgb2_best_f1 = XGB_pipeline_kfold_GridSearchCV(X,y,10*i,4)\n",
    "        print(\"________________________________________________________\")\n",
    "        print(\"Random State:\",10*i)\n",
    "        print(\"Best Parameters:\")\n",
    "        print(xgb2_grid.best_params_)\n",
    "        print('best CV score:',xgb2_grid.best_score_)\n",
    "        print('average precision score:',xgb2_ap_score)\n",
    "        print('precision: ', xgb2_best_precision)\n",
    "        print('recall: ', xgb2_best_recall)\n",
    "        print('f1: ', xgb2_best_f1)\n",
    "        xgb2_ap_scores.append(xgb2_ap_score)\n",
    "        xgb2_precision_scores.append(xgb2_best_precision)\n",
    "        xgb2_recall_scores.append(xgb2_best_recall)\n",
    "        xgb2_f1_scores.append(xgb2_best_f1)\n",
    "        xgb2_models.append(xgb2_best_model)\n",
    "        print(\"________________________________________________________\")\n",
    "    print(\"________________________________________________________\")\n",
    "    print('XGBoost No Impute Model Results')\n",
    "    print('test average precision :',np.around(np.mean(xgb2_ap_scores),2),'+/-',np.around(np.std(xgb2_ap_scores),2))\n",
    "    print('test precision :',np.around(np.mean(xgb2_precision_scores),2),'+/-',np.around(np.std(xgb2_precision_scores),2))\n",
    "    print('test recall: ',np.around(np.mean(xgb2_recall_scores),2),'+/-',np.around(np.std(xgb2_recall_scores),2))\n",
    "    print('test f1: ',np.around(np.mean(xgb2_f1_scores),2),'+/-',np.around(np.std(xgb2_f1_scores),2))\n",
    "    return xgb2_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost Model\n",
      "Iteration 0\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 673 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1293 out of 1296 | elapsed:  1.3min remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 0\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.01, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.5643895348837209\n",
      "average precision score: 0.25843881856540085\n",
      "precision:  0.5\n",
      "recall:  0.5\n",
      "f1:  0.5\n",
      "________________________________________________________\n",
      "Iteration 1\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 10\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.01, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.21433814893117217\n",
      "average precision score: 0.8\n",
      "precision:  0.8\n",
      "recall:  1.0\n",
      "f1:  0.888888888888889\n",
      "________________________________________________________\n",
      "Iteration 2\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 20\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 0.5, 'clf__learning_rate': 0.05, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 0.5}\n",
      "best CV score: 0.1379492600422833\n",
      "average precision score: 0.2626582278481013\n",
      "precision:  1.0\n",
      "recall:  0.25\n",
      "f1:  0.4\n",
      "________________________________________________________\n",
      "Iteration 3\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 30\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 0.75, 'clf__learning_rate': 0.1, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.2296996124031008\n",
      "average precision score: 0.13765822784810128\n",
      "precision:  0.5\n",
      "recall:  0.25\n",
      "f1:  0.3333333333333333\n",
      "________________________________________________________\n",
      "Iteration 4\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 40\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 0.5, 'clf__learning_rate': 0.05, 'clf__max_depth': 4, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.4861698379140239\n",
      "average precision score: 0.13765822784810128\n",
      "precision:  0.5\n",
      "recall:  0.25\n",
      "f1:  0.3333333333333333\n",
      "________________________________________________________\n",
      "Iteration 5\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   47.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 50\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.01, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 0.75}\n",
      "best CV score: 0.6345093375616632\n",
      "average precision score: 0.13765822784810128\n",
      "precision:  0.5\n",
      "recall:  0.25\n",
      "f1:  0.3333333333333333\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "XGBoost No Impute Model Results\n",
      "test average precision : 0.29 +/- 0.24\n",
      "test precision : 0.63 +/- 0.2\n",
      "test recall:  0.42 +/- 0.28\n",
      "test f1:  0.46 +/- 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "models = train_models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models):\n",
    "    predictions = []\n",
    "    for pipe in models:\n",
    "        predictions.append(pipe.predict_proba(X_2019)[:,1])\n",
    "    predictions = np.asarray(predictions)\n",
    "    final_preds = np.mean(predictions, axis=0)\n",
    "    win_score = [np.around(100*x,1) for x in final_preds]\n",
    "    movies_19 = list(mv['movie'].loc[oscars_2019])\n",
    "    pred_19 = pd.DataFrame(list(zip(movies_19,win_score)), columns = ['movie', 'win_prob'])\n",
    "    best_pic_noms = ['Black Panther', 'BlacKkKlansman', 'Bohemian Rhapsody', 'The Favourite', 'Green Book', 'Roma', 'A Star Is Born', 'Vice']\n",
    "    nom_preds = pred_19[pred_19['movie'].isin(best_pic_noms)]\n",
    "    nom_preds = nom_preds.sort_values(by='win_prob',ascending=False)\n",
    "    return nom_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>win_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Roma</td>\n",
       "      <td>36.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Favourite</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black Panther</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Star Is Born</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Vice</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Green Book</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BlacKkKlansman</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bohemian Rhapsody</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                movie  win_prob\n",
       "20               Roma      36.6\n",
       "14      The Favourite      18.7\n",
       "4       Black Panther      13.9\n",
       "1      A Star Is Born      13.3\n",
       "21               Vice      11.6\n",
       "32         Green Book      10.8\n",
       "36     BlacKkKlansman      10.3\n",
       "3   Bohemian Rhapsody       9.9"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
