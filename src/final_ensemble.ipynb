{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, recall_score, precision_score, \\\n",
    "    confusion_matrix, fbeta_score, average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "import xgboost\n",
    "import seaborn as sn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jovyan/data1030/data1030-oscars-prediction-project/data/pre_training_data.csv')\n",
    "label = 'Oscar_Best_Picture_won'\n",
    "y = df[label]\n",
    "X = df.drop(columns=['movie'])\n",
    "\n",
    "num_cols = 'duration,rate,metascore,votes,gross,user_reviews,critic_reviews,popularity,awards_nominations,Oscar_nominated,Golden_Globes_nominated,BAFTA_won,BAFTA_nominated,Screen_Actors_Guild_won,Screen_Actors_Guild_nominated,Critics_Choice_won,Critics_Choice_nominated,Directors_Guild_won,Directors_Guild_nominated,Producers_Guild_won,Producers_Guild_nominated,Art_Directors_Guild_won,Art_Directors_Guild_nominated,Writers_Guild_won,Writers_Guild_nominated,Costume_Designers_Guild_won,Costume_Designers_Guild_nominated,Online_Film_Television_Association_won,Online_Film_Television_Association_nominated,Online_Film_Critics_Society_won,Online_Film_Critics_Society_nominated,People_Choice_won,People_Choice_nominated,London_Critics_Circle_Film_won,London_Critics_Circle_Film_nominated,American_Cinema_Editors_won,American_Cinema_Editors_nominated,Hollywood_Film_won,Hollywood_Film_nominated,Austin_Film_Critics_Association_won,Austin_Film_Critics_Association_nominated,Denver_Film_Critics_Society_won,Denver_Film_Critics_Society_nominated,Boston_Society_of_Film_Critics_won,Boston_Society_of_Film_Critics_nominated,New_York_Film_Critics_Circle_won,New_York_Film_Critics_Circle_nominated,Los_Angeles_Film_Critics_Association_won,Los_Angeles_Film_Critics_Association_nominated'\n",
    "num_cols = [x for x in num_cols.split(',')]\n",
    "mis_cols = df.columns[df.isna().any()].tolist()\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = pd.read_csv('/home/jovyan/data1030/data1030-oscars-prediction-project/data/movies.csv')\n",
    "oscars_2019 = list(mv.index[mv['year'] == 2018])\n",
    "X_2019 = X.loc[oscars_2019]\n",
    "X_train = X.drop(oscars_2019)\n",
    "y_train = y.drop(oscars_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "def XGB_pipeline_kfold_GridSearchCV(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # continuous transformer setup\n",
    "    cnts_transformer = Pipeline(steps = [('ss', StandardScaler())])\n",
    "    # multivariate imputer setup\n",
    "    impute_transformer = Pipeline(steps = [('mi', IterativeImputer(estimator = \n",
    "                                RandomForestRegressor(n_estimators=100), random_state=random_state, missing_values = -999))])\n",
    "    # set up column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('num', cnts_transformer, num_cols)])\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    pipe = Pipeline(steps = [('preprocessor', preprocessor), ('clf', \n",
    "                        xgboost.XGBClassifier())])\n",
    "    #parameters to tune\n",
    "    param_grid = {'clf__colsample_bytree': [0.5, 0.75, 1.0], \n",
    "                  'clf__max_depth':[2,4,6,8] , \n",
    "                  'clf__min_child_weight': [2,5,10],\n",
    "                  'clf__subsample': [0.5, 0.75, 1.0],\n",
    "                  'clf__learning_rate': [0.01, 0.05,0.1]}\n",
    "    #prepare scorers\n",
    "    scoring = {'recall': make_scorer(recall_score), 'precision' : make_scorer(precision_score), 'ap' : make_scorer(average_precision_score)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, scoring = scoring, refit = 'ap', #scoring = make_scorer(average_precision_score),\n",
    "                            cv=kf, return_train_score = True,iid=True, verbose=1, n_jobs=-1)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_pred = best_model.predict(X_test)\n",
    "    best_precision = precision_score(y_test, best_pred) \n",
    "    best_recall = recall_score(y_test, best_pred)\n",
    "    best_f1 = fbeta_score(y_test, best_pred, 1)\n",
    "    return grid, grid.score(X_test, y_test), best_model, best_pred, best_precision, best_recall, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X,y):    \n",
    "    xgb2_ap_scores = []\n",
    "    xgb2_precision_scores = []\n",
    "    xgb2_recall_scores = []\n",
    "    xgb2_f1_scores = []\n",
    "    xgb2_models = []\n",
    "\n",
    "    print(\"Training XGBoost Model\")\n",
    "    for i in range(6):\n",
    "        print(\"Iteration\", i)\n",
    "        xgb2_grid,xgb2_ap_score, xgb2_best_model, xgb2_best_pred, xgb2_best_precision, xgb2_best_recall, xgb2_best_f1 = XGB_pipeline_kfold_GridSearchCV(X,y,10*i,4)\n",
    "        print(\"________________________________________________________\")\n",
    "        print(\"Random State:\",10*i)\n",
    "        print(\"Best Parameters:\")\n",
    "        print(xgb2_grid.best_params_)\n",
    "        print('best CV score:',xgb2_grid.best_score_)\n",
    "        print('average precision score:',xgb2_ap_score)\n",
    "        print('precision: ', xgb2_best_precision)\n",
    "        print('recall: ', xgb2_best_recall)\n",
    "        print('f1: ', xgb2_best_f1)\n",
    "        xgb2_ap_scores.append(xgb2_ap_score)\n",
    "        xgb2_precision_scores.append(xgb2_best_precision)\n",
    "        xgb2_recall_scores.append(xgb2_best_recall)\n",
    "        xgb2_f1_scores.append(xgb2_best_f1)\n",
    "        xgb2_models.append(xgb2_best_model)\n",
    "        print(\"________________________________________________________\")\n",
    "    print(\"________________________________________________________\")\n",
    "    print('XGBoost No Impute Model Results')\n",
    "    print('test average precision :',np.around(np.mean(xgb2_ap_scores),2),'+/-',np.around(np.std(xgb2_ap_scores),2))\n",
    "    print('test precision :',np.around(np.mean(xgb2_precision_scores),2),'+/-',np.around(np.std(xgb2_precision_scores),2))\n",
    "    print('test recall: ',np.around(np.mean(xgb2_recall_scores),2),'+/-',np.around(np.std(xgb2_recall_scores),2))\n",
    "    print('test f1: ',np.around(np.mean(xgb2_f1_scores),2),'+/-',np.around(np.std(xgb2_f1_scores),2))\n",
    "    return xgb2_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost Model\n",
      "Iteration 0\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 673 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1293 out of 1296 | elapsed:  1.3min remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 0\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.01, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.5643895348837209\n",
      "average precision score: 0.25843881856540085\n",
      "precision:  0.5\n",
      "recall:  0.5\n",
      "f1:  0.5\n",
      "________________________________________________________\n",
      "Iteration 1\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 10\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.01, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.21433814893117217\n",
      "average precision score: 0.8\n",
      "precision:  0.8\n",
      "recall:  1.0\n",
      "f1:  0.888888888888889\n",
      "________________________________________________________\n",
      "Iteration 2\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 20\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 0.5, 'clf__learning_rate': 0.05, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 0.5}\n",
      "best CV score: 0.1379492600422833\n",
      "average precision score: 0.2626582278481013\n",
      "precision:  1.0\n",
      "recall:  0.25\n",
      "f1:  0.4\n",
      "________________________________________________________\n",
      "Iteration 3\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 30\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 0.75, 'clf__learning_rate': 0.1, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.2296996124031008\n",
      "average precision score: 0.13765822784810128\n",
      "precision:  0.5\n",
      "recall:  0.25\n",
      "f1:  0.3333333333333333\n",
      "________________________________________________________\n",
      "Iteration 4\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   48.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 40\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 0.5, 'clf__learning_rate': 0.05, 'clf__max_depth': 4, 'clf__min_child_weight': 2, 'clf__subsample': 1.0}\n",
      "best CV score: 0.4861698379140239\n",
      "average precision score: 0.13765822784810128\n",
      "precision:  0.5\n",
      "recall:  0.25\n",
      "f1:  0.3333333333333333\n",
      "________________________________________________________\n",
      "Iteration 5\n",
      "Fitting 4 folds for each of 324 candidates, totalling 1296 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:   47.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Random State: 50\n",
      "Best Parameters:\n",
      "{'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.01, 'clf__max_depth': 2, 'clf__min_child_weight': 2, 'clf__subsample': 0.75}\n",
      "best CV score: 0.6345093375616632\n",
      "average precision score: 0.13765822784810128\n",
      "precision:  0.5\n",
      "recall:  0.25\n",
      "f1:  0.3333333333333333\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "XGBoost No Impute Model Results\n",
      "test average precision : 0.29 +/- 0.24\n",
      "test precision : 0.63 +/- 0.2\n",
      "test recall:  0.42 +/- 0.28\n",
      "test f1:  0.46 +/- 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1296 out of 1296 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "models = train_models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(models):\n",
    "    predictions = []\n",
    "    for pipe in models:\n",
    "        predictions.append(pipe.predict_proba(X_2019)[:,1])\n",
    "    predictions = np.asarray(predictions)\n",
    "    final_preds = np.mean(predictions, axis=0)\n",
    "    win_score = [np.around(100*x,1) for x in final_preds]\n",
    "    movies_19 = list(mv['movie'].loc[oscars_2019])\n",
    "    pred_19 = pd.DataFrame(list(zip(movies_19,win_score)), columns = ['movie', 'win_prob'])\n",
    "    best_pic_noms = ['Black Panther', 'BlacKkKlansman', 'Bohemian Rhapsody', 'The Favourite', 'Green Book', 'Roma', 'A Star Is Born', 'Vice']\n",
    "    nom_preds = pred_19[pred_19['movie'].isin(best_pic_noms)]\n",
    "    nom_preds = nom_preds.sort_values(by='win_prob',ascending=False)\n",
    "    return nom_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>win_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Roma</td>\n",
       "      <td>36.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Favourite</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Black Panther</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Star Is Born</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Vice</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Green Book</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BlacKkKlansman</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bohemian Rhapsody</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                movie  win_prob\n",
       "20               Roma      36.6\n",
       "14      The Favourite      18.7\n",
       "4       Black Panther      13.9\n",
       "1      A Star Is Born      13.3\n",
       "21               Vice      11.6\n",
       "32         Green Book      10.8\n",
       "36     BlacKkKlansman      10.3\n",
       "3   Bohemian Rhapsody       9.9"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
